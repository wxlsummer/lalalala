{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Sourcecode_OP.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyO+gRvy9CH4bDCHXgNbO30y"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"9sNiQtcB5tKh"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":53},"id":"YrK7PSlMTr2_","executionInfo":{"status":"ok","timestamp":1630314085496,"user_tz":-60,"elapsed":21715,"user":{"displayName":"xiaoliang wu","photoUrl":"","userId":"16674103219706460675"}},"outputId":"b8b11c32-d8e9-462c-a181-ace61c86ea77"},"source":["import tensorflow as tf\n","from google.colab import drive\n","\n","# 使用工具colab的接口挂载google drive目录，这样可以从外部获取数据并且可以把训练好的模型保存在google drive上\n","drive.mount('/content/gdrive')\n","tf.test.gpu_device_name()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive\n"],"name":"stdout"},{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'/device:GPU:0'"]},"metadata":{},"execution_count":1}]},{"cell_type":"markdown","metadata":{"id":"Yw0YwHomn-zK"},"source":["The code to compute PSD and masking threshold"]},{"cell_type":"code","metadata":{"id":"oHt9inNnn9RD"},"source":["import scipy.io.wavfile as wav\n","import numpy as np\n","from scipy.fftpack import fft\n","from scipy.fftpack import ifft\n","from scipy import signal\n","import scipy\n","import librosa\n","\n","def compute_PSD_matrix(audio, window_size):\n","    \"\"\"\n","\tFirst, perform STFT.\n","\tThen, compute the PSD.\n","\tLast, normalize PSD.\n","    \"\"\"\n","\n","    win = np.sqrt(8.0/3.) * librosa.core.stft(audio, center=False)\n","    stft=librosa.core.stft(audio, center=False)\n","    magnitude, phase = librosa.magphase(stft)\n","    z = abs(win / window_size)\n","    psd_max = np.max(z*z)\n","    psd = 10 * np.log10(z * z + 0.0000000000000000001)\n","    PSD = 96 - np.max(psd) + psd\n","    return win,z,PSD, psd_max, np.max(psd),phase,stft\n","\n","def Bark(f):\n","    \"\"\"returns the bark-scale value for input frequency f (in Hz)\"\"\"\n","    return 13*np.arctan(0.00076*f) + 3.5*np.arctan(pow(f/7500.0, 2))\n","\n","def quiet(f):\n","     \"\"\"returns threshold in quiet measured in SPL at frequency f with an offset 12(in Hz)\"\"\"\n","     thresh = 3.64*pow(f*0.001,-0.8) - 6.5*np.exp(-0.6*pow(0.001*f-3.3,2)) + 0.001*pow(0.001*f,4) - 12\n","     return thresh\n","\n","def two_slops(bark_psd, delta_TM, bark_maskee):\n","    \"\"\"\n","\treturns the masking threshold for each masker using two slopes as the spread function \n","    \"\"\"\n","    Ts = []\n","    for tone_mask in range(bark_psd.shape[0]):\n","        bark_masker = bark_psd[tone_mask, 0]\n","        dz = bark_maskee - bark_masker\n","        zero_index = np.argmax(dz > 0)\n","        sf = np.zeros(len(dz))\n","        sf[:zero_index] = 27 * dz[:zero_index]\n","        sf[zero_index:] = (-27 + 0.37 * max(bark_psd[tone_mask, 1] - 40, 0)) * dz[zero_index:] \n","        T = bark_psd[tone_mask, 1] + delta_TM[tone_mask] + sf\n","        Ts.append(T)\n","    return Ts\n","    \n","def compute_th(PSD, barks, ATH, freqs):\n","    \"\"\" returns the global masking threshold\n","    \"\"\"\n","    # Identification of tonal maskers\n","    # find the index of maskers that are the local maxima\n","    length = len(PSD)\n","    masker_index = signal.argrelextrema(PSD, np.greater)[0]\n","    \n","    \n","    # delete the boundary of maskers for smoothing\n","    if 0 in masker_index:\n","        masker_index = np.delete(0)\n","    if length - 1 in masker_index:\n","        masker_index = np.delete(length - 1)\n","    num_local_max = len(masker_index)\n","\n","    # treat all the maskers as tonal (conservative way)\n","    # smooth the PSD \n","    p_k = pow(10, PSD[masker_index]/10.)    \n","    p_k_prev = pow(10, PSD[masker_index - 1]/10.)\n","    p_k_post = pow(10, PSD[masker_index + 1]/10.)\n","    P_TM = 10 * np.log10(p_k_prev + p_k + p_k_post)\n","    \n","    # bark_psd: the first column bark, the second column: P_TM, the third column: the index of points\n","    _BARK = 0\n","    _PSD = 1\n","    _INDEX = 2\n","    bark_psd = np.zeros([num_local_max, 3])\n","    bark_psd[:, _BARK] = barks[masker_index]\n","    bark_psd[:, _PSD] = P_TM\n","    bark_psd[:, _INDEX] = masker_index\n","    \n","    # delete the masker that doesn't have the highest PSD within 0.5 Bark around its frequency \n","    for i in range(num_local_max):\n","        next = i + 1\n","        if next >= bark_psd.shape[0]:\n","            break\n","            \n","        while bark_psd[next, _BARK] - bark_psd[i, _BARK]  < 0.5:\n","            # masker must be higher than quiet threshold\n","            if quiet(freqs[int(bark_psd[i, _INDEX])]) > bark_psd[i, _PSD]:\n","                bark_psd = np.delete(bark_psd, (i), axis=0)\n","            if next == bark_psd.shape[0]:\n","                break\n","                \n","            if bark_psd[i, _PSD] < bark_psd[next, _PSD]:\n","                bark_psd = np.delete(bark_psd, (i), axis=0)\n","            else:\n","                bark_psd = np.delete(bark_psd, (next), axis=0)\n","            if next == bark_psd.shape[0]:\n","                break        \n","    \n","    # compute the individual masking threshold\n","    delta_TM = 1 * (-6.025  -0.275 * bark_psd[:, 0])\n","    Ts = two_slops(bark_psd, delta_TM, barks) \n","    Ts = np.array(Ts)\n","    \n","    # compute the global masking threshold\n","    theta_x = np.sum(pow(10, Ts/10.), axis=0) + pow(10, ATH/10.) \n"," \n","    return theta_x\n","\n","def generate_th(audio, fs, window_size=2048):\n","    \"\"\"\n","\treturns the masking threshold theta_xs and the max psd of the audio\n","    \"\"\"\n","    win,z,PSD, psd_max, max_,phase,stft= compute_PSD_matrix(audio , window_size)  \n","    freqs = librosa.core.fft_frequencies(fs, window_size)\n","    barks = Bark(freqs)\n","\n","    # compute the quiet threshold \n","    ATH = np.zeros(len(barks)) - np.inf\n","    bark_ind = np.argmax(barks > 1)\n","    ATH[bark_ind:] = quiet(freqs[bark_ind:])\n","\n","    # compute the global masking threshold theta_xs \n","    theta_xs = []\n","    # compute the global masking threshold in each window\n","    for i in range(PSD.shape[1]):\n","        theta_xs.append(compute_th(PSD[:,i], barks, ATH, freqs))\n","    theta_xs = np.array(theta_xs)\n","    return win,z, PSD,theta_xs, psd_max,max_,phase,stft"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5w2Lm8Q8jAk2"},"source":["This is meant to generate the adversarial audio using All frames "]},{"cell_type":"code","metadata":{"id":"5AjV1NpYiVpc"},"source":["import os\n","import wave\n","import librosa\n","import scipy.io.wavfile as wav\n","import numpy as np\n"," \n","def add_noise(audio_path):\n","\n","  #audio_path='/content/gdrive/MyDrive/deepspeech/audios_wav/19-198-0001.wav'\n","  print(audio_path)\n","  scale = 8. / 3.\n","  window_size=2048\n","  frame_length = 2048\n","  frame_step = 512\n","  fs, data_true = wav.read(audio_path)\n","  length=len(data_true)\n","  data_true=data_true.reshape((length,)).astype(np.float64)\n","  win_ori,z_ori,PSD, theta_xs, psd_max, max_,phase,stft=generate_th(data_true, fs)\n","  print(length)\n","  print(\"PSD\",PSD.shape)\n","  print(win_ori.shape)\n","  print(\"THETA_XS\",theta_xs.shape)\n","\n","  theta_xs_=theta_xs.transpose()\n","  a=theta_xs_*psd_max.reshape([-1, 1, 1])\n","  b=pow(10., 9.6)\n","  psd=a/b\n","  z_=np.sqrt(psd)/scale*2048.0\n","  print(z_.shape)\n","  z=z_.reshape((z_.shape[1],z_.shape[2]))\n","  #print(z)\n","  #y_inv = librosa.griffinlim(z)\n","\n","  istft=z*phase\n","  y_inv=librosa.core.istft(istft)\n","  data_pad=copy.deepcopy(data_true)\n","  #print(data_pad)\n","  print(y_inv)\n","  for i in range(len(y_inv)):\n","    data_pad[i]+=y_inv[i]\n","\n","  data_pad=data_pad.astype(np.int16)\n","  return data_pad\n","  #wavfile.write(\"/content/gdrive/MyDrive/deepspeech/audios_all_wav/19-198-0001.wav\", fs, data_pad)\n","\n","\n","name=\"sample.wav\"\n","path_noise=\"OP_all.wav\"\n","\n","print(\"add noise File Name is \", name)\n","data_noise = add_noise(name)\n","\n","wav.write(path_noise,fs, data_noise)\n","\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6sakzcasjyrh"},"source":["This is meant to generate the adversarial audio using Important frames. But you need to generate all frames adversarial sample and important frames list first by using frameselection.ipynb."]},{"cell_type":"code","metadata":{"id":"q1ADmD58jw3e"},"source":["import numpy as np  \n","import numpy as np\n","# save np.load\n","np_load_old = np.load\n","\n","# modify the default parameters of np.load\n","np.load = lambda *a,**k: np_load_old(*a, allow_pickle=True, **k)\n","\n","path_index=\"index.npy\"\n","# call load_data with allow_pickle implicitly set to true\n","index_list = np.load(path_index) \n","\n","# restore np.load for future normal usage\n","np.load = np_load_old\n","#error_list = np.load(\"/content/gdrive/MyDrive/deepspeech/error_all.npy\") \n","#print(error_list)  \n","\n","indexlist=index_list.tolist()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CnJ4OdYDkmfr"},"source":["from scipy.io import wavfile\n","import numpy as np\n","from scipy.fftpack import fft\n","from scipy.fftpack import ifft\n","from scipy import signal\n","import scipy\n","import copy\n","import os\n","\n","url_already_audio=path_noise\n","#path_noise is the path of the adversarial sample using GL and ALL \n","url_original_audio=name\n","\n","url = \"Important_OP.wav\"\n","\n","\n","original_url=url_original_audio\n","all_url=url_already_audio\n","fs, data_true = wavfile.read(original_url)\n","fs, data_all = wavfile.read(all_url)\n","data_final=copy.deepcopy(data_true)\n","data_n=(len(data_true)-1536)//512\n","\n","n=1\n","index_=indexlist\n","num_frames=n*len(index_)\n","#index_random=int_random(0,data_n,num_frames)\n","#print(index_random)\n","#print(data_true[0*n*512:1*n*512])\n","\n","for item in index_:\n","  \n","  data_final[item*512*n:(item+1)*512*n]=copy.deepcopy(data_all[item*512*n:(item+1)*512*n])\n","\n","wavfile.write(url, fs, data_final)\n","print(\"============================================================================\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QbHbsCUPl7AU"},"source":["This is meant to generate the adversarial audio using Random frames. But you need to generate all frames adversarial sample and important frames list first by using frameselection.ipynb."]},{"cell_type":"code","metadata":{"id":"DAYl7L6YmNhi"},"source":["import numpy as np  \n","import numpy as np\n","# save np.load\n","np_load_old = np.load\n","\n","# modify the default parameters of np.load\n","np.load = lambda *a,**k: np_load_old(*a, allow_pickle=True, **k)\n","\n","path_index=\"index.npy\"\n","# call load_data with allow_pickle implicitly set to true\n","index_list = np.load(path_index) \n","\n","# restore np.load for future normal usage\n","np.load = np_load_old\n","#error_list = np.load(\"/content/gdrive/MyDrive/deepspeech/error_all.npy\") \n","#print(error_list)  \n","\n","indexlist=index_list.tolist()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"I06Kzj-2mH_C"},"source":["from scipy.io import wavfile\n","import numpy as np\n","from scipy.fftpack import fft\n","from scipy.fftpack import ifft\n","from scipy import signal\n","import scipy\n","import copy\n","import os\n","\n","url_already_audio=path_noise\n","url_original_audio=name\n","\n","url = \"Random_OP.wav\"\n","\n","\n","original_url=url_original_audio\n","all_url=url_already_audio\n","fs, data_true = wavfile.read(original_url)\n","fs, data_all = wavfile.read(all_url)\n","data_final=copy.deepcopy(data_true)\n","data_n=(len(data_true)-1536)//512\n","\n","index_all=[i for i in range(data_n)]\n","#index_all=range(0,data_n)\n","n=1\n","index_=indexlist\n","num_frames=n*len(index_)\n","for i in index_:\n","  for j in range(n):\n","    index_all.remove(i*n+j)\n","  #del index_all[i*n:i*(n+1)]\n","if(len(index_all)>=num_frames):\n","  index_random=random.sample(index_all,num_frames)\n","else:\n","  index_random=index_all\n","#index_random=int_random(0,data_n,num_frames)\n","#print(data_true[0*n*512:1*n*512])\n","\n","for item in index_random:\n","  \n","  data_final[item*512:(item+1)*512]=copy.deepcopy(data_all[item*512:(item+1)*512])\n","\n","wavfile.write(url, fs, data_final)\n","print(\"============================================================================\")"],"execution_count":null,"outputs":[]}]}