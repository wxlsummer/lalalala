{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"frameselection.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1J3zWTJtCL39OSaJKc3zQ6YM1P7gOIYit","authorship_tag":"ABX9TyPQWsjjmhe0woBAqPdUN7UO"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"L0kL2jW_2bXM"},"source":["!wget -O git-lfs.tar.gz https://github.com/git-lfs/git-lfs/releases/download/v2.4.2/git-lfs-linux-amd64-2.4.2.tar.gz\n","!tar -xvzf git-lfs.tar.gz\n","!./git-lfs-2.4.2/install.sh\n","!git lfs clone https://github.com/mozilla/deepspeech\n","%cd deepspeech\n","!git checkout -f tags/v0.7.3\n","%cd .."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Jlr2BKUY3WlW"},"source":["\n","#download the requirements\n","\n","!pip3 install -r deepspeech/requirements_transcribe.txt\n","!pip3 install -r deepspeech/requirements_tests.txt\n","!pip3 install -r deepspeech/requirements_eval_tflite.txt\n","!pip3 install deepspeech-gpu==0.7.3\n","\n","!pip3 uninstall tensorflow -y\n","!pip3 install tensorflow-gpu==1.15.2\n","!pip3 install ds_ctcdecoder==0.7.3\n","%cd deepspeech\n","\n","!pip3 install -e .  # install reqs if missed any\n","%cd .."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zWgLdxfy6R0G"},"source":["# download sample data for testing the deepspeech model\n","\n","!wget https://www.dropbox.com/sh/7wp15mwmuv6exdj/AAAb7LJE0jBGyJ0titPZ1jDZa?dl=0\n","!mv 'AAAb7LJE0jBGyJ0titPZ1jDZa?dl=0' data.tar\n","!unzip data.tar\n","!ls"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2BO2AMDE6cDH"},"source":["#download pretrained model and scorer\n","!wget https://github.com/mozilla/DeepSpeech/releases/download/v0.7.0/deepspeech-0.7.0-models.pbmm\n","!wget https://github.com/mozilla/DeepSpeech/releases/download/v0.7.0/deepspeech-0.7.0-models.scorer"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":52},"id":"oVQDtjPvK-pW","executionInfo":{"status":"ok","timestamp":1633163506953,"user_tz":-60,"elapsed":20795,"user":{"displayName":"xiaoliang wu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16674103219706460675"}},"outputId":"d320cca8-deae-4c4c-98d2-f5f96e66578c"},"source":["import tensorflow as tf\n","from google.colab import drive\n","\n","# 使用工具colab的接口挂载google drive目录，这样可以从外部获取数据并且可以把训练好的模型保存在google drive上\n","drive.mount('/content/gdrive')\n","tf.test.gpu_device_name()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]},{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'/device:GPU:0'"]},"metadata":{},"execution_count":1}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MEveaxyw6fL3","executionInfo":{"status":"ok","timestamp":1632035806732,"user_tz":-60,"elapsed":6240,"user":{"displayName":"xiaoliang wu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16674103219706460675"}},"outputId":"e90c39d4-4f16-4d2a-8183-1a680134a8c5"},"source":["!pip3 install jiwer\n","from jiwer import wer"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting jiwer\n","  Downloading jiwer-2.2.0-py3-none-any.whl (13 kB)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from jiwer) (1.19.5)\n","Collecting python-Levenshtein\n","  Downloading python-Levenshtein-0.12.2.tar.gz (50 kB)\n","\u001b[?25l\r\u001b[K     |██████▌                         | 10 kB 34.3 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 20 kB 26.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 30 kB 17.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 40 kB 15.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 50 kB 4.1 MB/s \n","\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from python-Levenshtein->jiwer) (57.4.0)\n","Building wheels for collected packages: python-Levenshtein\n","  Building wheel for python-Levenshtein (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for python-Levenshtein: filename=python_Levenshtein-0.12.2-cp37-cp37m-linux_x86_64.whl size=149865 sha256=e56c46ea2d7f76dd5275abd465f487cd2d46b2bf9a94301ba805304e57e78ef1\n","  Stored in directory: /root/.cache/pip/wheels/05/5f/ca/7c4367734892581bb5ff896f15027a932c551080b2abd3e00d\n","Successfully built python-Levenshtein\n","Installing collected packages: python-Levenshtein, jiwer\n","Successfully installed jiwer-2.2.0 python-Levenshtein-0.12.2\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"atbkQ6vhwVOO","executionInfo":{"status":"ok","timestamp":1629359863063,"user_tz":-60,"elapsed":314,"user":{"displayName":"xiaoliang wu","photoUrl":"","userId":"16674103219706460675"}},"outputId":"c8ddad19-195b-4d1e-95d8-b5cd12fbeefa"},"source":["tf.test.gpu_device_name()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'/device:GPU:0'"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","metadata":{"id":"mFJU170-eFPn"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BDdzdF-FkRHg"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RSoOnSBL6vVX"},"source":["\n","from deepspeech import Model\n","import scipy.io.wavfile as wav\n","import pandas as pd\n","dsModel = Model(\"deepspeech-0.7.0-models.pbmm\")\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jiuQYF7SHyzj","executionInfo":{"status":"ok","timestamp":1628665645231,"user_tz":-60,"elapsed":9674,"user":{"displayName":"xiaoliang wu","photoUrl":"","userId":"16674103219706460675"}},"outputId":"b2b299dc-88a5-48b0-fcd5-1c3d0894df94"},"source":["path=\"sample.wav\"\n","\n","fs, audio = wav.read(path)\n","output = dsModel.stt(audio)\n","print(\"Deepspeech Transcription: \", output)\n","#print(\"Actual Transcription: \", row['Transcription'])\n","print(\"-----------------------------------------------------------------------------------\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Deepspeech Transcription:  this little work was finished in the year eighteen o three and intended for a mediate publication it was disposed of to a bookseller it was even advertised\n","-----------------------------------------------------------------------------------\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"rXhO-7fBGo-X"},"source":["#import speech_recognition as sr\n","from os import path\n","import os.path\n","import operator\n","from os import system\n","from os import listdir\n","from os.path import isfile, join\n","import wave\n","import scipy as sc\n","import librosa\n","import IPython.display as ipd\n","import numpy as np\n","from PIL import Image\n","import matplotlib.pyplot as plt\n","import matplotlib\n","import numpy as np\n","%matplotlib inline\n","import math\n","import librosa as lb\n","import scipy\n","from sklearn.decomposition import PCA\n","import pandas as pd\n","from os import listdir\n","from os.path import isfile, join\n","import time\n","from itertools import product\n","import datetime\n","import sys\n","import os\n","#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fyg2EtEZtb6U"},"source":["from deepspeech import Model\n","from scipy.io import wavfile\n","\n","def transcribe_deepspeech(my_path):\n","    #audio_path = 'audio/2830-3980-0043.wav'\n","    audio_path=my_path\n","    fs, data = wavfile.read(audio_path)\n","    data=data.astype(np.int16)\n","    #model_path = \"C:/Users/wuxia/ad_samples/deepspeech-0.6.0-models/output_graph.pb\" # 已下载的模型地址（正确的模型文件中有以.pb结尾的文件）\n","    #ars = Model(model_path,2048) # 1024应该是指窗长，这个是在源码中看到了\n","    dsModel = Model(\"deepspeech-0.7.0-models.pbmm\")\n","    translate_txt = dsModel.stt(data)\n","\n","    print(translate_txt)\n","    return translate_txt"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WyT_ZYGItk5M"},"source":["def create_wav(name,data):\n","    \n","    #url_wav='/content/gdrive/MyDrive/deepspeech/audio_temp/'+name+'temp.wav'\n","    url_wav=name\n","    wavfile.write(url_wav, 16000, data)\n","    return url_wav"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"o_hzUJFl72hl"},"source":["import os\n","def framing(name,n,data):\n","    \n","    transcription=[]\n","\n","    for i in range(0,n):\n","        temp=np.copy(data)\n","        if i< n-1:\n","            for j in range(512):\n","                temp[i*512+j]=0\n","        if i==n-1:\n","            for j in range(2048):\n","                temp[i*512+j]=0\n","        #str_=\"audio/sample4507_framing/frame_%d.wav\"\n","        str_=create_wav(name,temp)\n","        #scipy.io.wavfile.write(str_, fs, temp)\n","        trans_x=transcribe_deepspeech(str_)\n","        print(\"%d th frame is set to all 0s.\" %i)\n","        print(trans_x)\n","        transcription.append(trans_x)\n","        print(transcription)\n","    return transcription"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uGOKkYZfAQP9"},"source":["import os\n","#import wave\n","from jiwer import wer\n","import numpy as np\n","\n","path=\"sample.wav\"\n","\n","fs, data = scipy.io.wavfile.read(path)\n","print(data.shape)\n","elementsInBucket = 2048\n","n = int((len(data)-2048+512)/512)\n","print(n)\n","name,category=os.path.splitext(\"sample.wav\")\n","    \n","#name,category=os.path.splitext(filepath+filename)#分解文件扩展名\n","\n","print(name)\n","\n","url_wav_2=name+'_temp.wav'\n","transcription=framing(url_wav_2,n,data)\n","\n","\n","\n","\n","indexlist=[]\n","\n","for i in range(len(transcription)):\n","  if(wer(output, transcription[i])>0):\n","    indexlist.append(i)\n","\n","\n","\n","np.save(\"index.npy\",np.array(indexlist))\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DPrqgcOrHuTP"},"source":["import os\n","df=pd.read_csv('sample_data.csv')  # read the csv file\n","for i,row in df.iterrows():\n","  # resample the input file to 16KHz\n","  command=\"ffmpeg -i \"+row['File_Path'] +\"-ar 16000 -acodec pcm_s16le -ac 1 \"+row['File_Path']\n","  os.system(command)\n","  fs, audio = wav.read(row['File_Path'])  # do inference with deepspeech\n","  output = dsModel.stt(audio)\n","  print(\"Deepspeech Transcription: \", output)\n","  print(\"Actual Transcription: \", row['Transcription'])\n","  print(\"-----------------------------------------------------------------------------------\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YAq2d_tTHSif"},"source":[""],"execution_count":null,"outputs":[]}]}